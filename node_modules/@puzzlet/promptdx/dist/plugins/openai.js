import { ModelPlugin } from "../model-plugin";
import OpenAI from "openai";
import { getEnv, omit, toFrontMatter } from "../utils";
export class OpenAIChatPlugin extends ModelPlugin {
    constructor() {
        super("openai");
    }
    deserialize(promptDX) {
        return refineChatCompletionParams({
            messages: promptDX.messages,
            model: promptDX.metadata.model.name,
            ...promptDX.metadata.model.settings,
        });
    }
    serialize(completionParams, name) {
        const { model, messages, ...settings } = completionParams;
        const mdxArr = [];
        const frontMatter = toFrontMatter({
            name: name,
            metadata: {
                model: {
                    name: model,
                    settings,
                },
            },
        });
        mdxArr.push(frontMatter);
        messages.forEach((message) => {
            const role = message.role;
            const JSXTag = role[0].toUpperCase() + role.slice(1);
            if (JSXTag) {
                mdxArr.push(`<${JSXTag}>${message.content}</${JSXTag}>`);
            }
        });
        return mdxArr.join('\n');
    }
    async runInference(completionParams) {
        const apiKey = this.apiKey || getEnv("OPENAI_API_KEY");
        if (!apiKey) {
            throw new Error("No API key provided");
        }
        const client = new OpenAI({ apiKey });
        const { stream = false } = completionParams;
        if (!stream) {
            completionParams.stream = false;
            const response = await client.chat.completions.create(completionParams);
            const outputs = response.choices
                .map((choice) => {
                const outputData = buildOutputData(choice.message);
                if (outputData == undefined)
                    return null;
                return {
                    output_type: "execute_result",
                    data: outputData,
                    execution_count: choice.index,
                    metadata: {
                        finish_reason: choice.finish_reason,
                        ...omit(response, "choices"),
                        raw_response: choice.message,
                        ...omit(choice.message, "content", "function_call"),
                    },
                };
            })
                .filter(Boolean);
            return outputs;
        }
        else {
            completionParams.stream = true;
            const responseStream = await client.chat.completions.create(completionParams);
            const outputs = new Map();
            let messages = new Map();
            for await (const chunk of responseStream) {
                messages = multiChoiceMessageReducer(messages, chunk);
                chunk.choices.forEach((choice) => {
                    const message = messages.get(choice.index);
                    if (!message)
                        return;
                    const outputData = buildOutputData(message);
                    if (!outputData)
                        return;
                    const output = {
                        output_type: "execute_result",
                        data: outputData,
                        execution_count: choice.index,
                        metadata: {
                            finish_reason: choice.finish_reason,
                            raw_response: message,
                        },
                    };
                    outputs.set(choice.index, output);
                });
            }
            return Array.from(outputs.values());
        }
    }
}
function refineChatCompletionParams(params) {
    const allowedKeys = [
        "model",
        "messages",
        "functions",
        "tools",
        "function_call",
        "temperature",
        "top_p",
        "n",
        "stream",
        "stop",
        "max_tokens",
        "presence_penalty",
        "frequency_penalty",
        "logit_bias",
        "user",
    ];
    const completionParams = {};
    for (const key of allowedKeys) {
        if (params[key] != null) {
            completionParams[key] = params[key];
        }
    }
    return completionParams;
}
function reduceMessages(acc, delta) {
    const result = { ...acc };
    for (const [key, value] of Object.entries(delta)) {
        if (result[key] == null) {
            result[key] = value;
        }
        else if (typeof result[key] === "string" && typeof value === "string") {
            result[key] += value;
        }
        else if (typeof result[key] === "object" && !Array.isArray(result[key])) {
            result[key] = reduceMessages(result[key], value);
        }
    }
    return result;
}
export function multiChoiceMessageReducer(messages, chunk) {
    if (messages.size !== 0 && messages.size !== chunk.choices.length) {
        throw new Error("Invalid number of previous choices -- it should match the incoming number of choices");
    }
    chunk.choices.forEach((choice) => {
        const previousMessage = messages.get(choice.index) || {};
        const updatedMessage = reduceMessages(previousMessage, choice.delta);
        messages.set(choice.index, updatedMessage);
    });
    return messages;
}
function buildOutputData(message) {
    var _a;
    if (!message)
        return undefined;
    if (message.content !== null) {
        if (typeof message.content === "string") {
            return message.content;
        }
        else if (Array.isArray(message.content)) {
            return message.content
                .map((msg) => {
                if (msg.type === "text")
                    return msg.text;
                if (msg.type === "image_url")
                    return msg.image_url;
                return undefined;
            })
                .join("\n");
        }
    }
    else if (message.role === "assistant") {
        const tool = (_a = message.tool_calls) === null || _a === void 0 ? void 0 : _a[0];
        if ((tool === null || tool === void 0 ? void 0 : tool.type) === "function") {
            return {
                kind: "tool_calls",
                value: [{ type: "function", function: tool.function }],
            };
        }
    }
    return undefined;
}
//# sourceMappingURL=openai.js.map